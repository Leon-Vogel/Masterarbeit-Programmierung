{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config_kmeans = {\n",
    "    \"jpl\": 20,  # Example values, please adjust according to your needs\n",
    "    \"conv_speed\": 208,\n",
    "    \"n_machines\": 12,\n",
    "    \"n_lines\": 1,\n",
    "    \"window_size\": 4,\n",
    "    \"isri_dataset\": 'isri_dataset',\n",
    "    \"next_n\": 15,\n",
    "    \"last_n\": 2,\n",
    "    \"input_features\": 13,  # Example number of features per job\n",
    "    \"obs_space\": 'simple', # simple, full, small\n",
    "    \"diffsum_weight\": 0.0, #diffsum im tausender Bereich\n",
    "    \"DIFFSUM_NORM\": 1.0,\n",
    "    \"tardiness_weight\": 1.0, \n",
    "    \"TARDINESS_NORM\": 1.0,\n",
    "    \"pca\": None,\n",
    "    \"n_classes\": 8, # Muss mit Kmeans übereinstimmen\n",
    "    \"cluster_method\": \"kmeans\" #kmeans model übergeben\n",
    "}\n",
    "\n",
    "env_config_neighbour = {\n",
    "    \"jpl\": 20,  # Example values, please adjust according to your needs\n",
    "    \"conv_speed\": 208,\n",
    "    \"n_machines\": 12,\n",
    "    \"n_lines\": 1,\n",
    "    \"window_size\": 4,\n",
    "    \"isri_dataset\": 'isri_dataset',\n",
    "    \"next_n\": 15,\n",
    "    \"last_n\": 2,\n",
    "    \"input_features\": 13,  # Example number of features per job\n",
    "    \"obs_space\": 'simple', # simple, full, small\n",
    "    \"diffsum_weight\": 0.0, #diffsum im tausender Bereich\n",
    "    \"DIFFSUM_NORM\": 1.0,\n",
    "    \"tardiness_weight\": 1.0, \n",
    "    \"TARDINESS_NORM\": 1.0,\n",
    "    \"pca\": None,\n",
    "    \"n_classes\": 8, # Muss mit Kmeans übereinstimmen\n",
    "    \"cluster_method\": \"neighbour\" #kmeans model übergeben\n",
    "}\n",
    "\n",
    "config_list = [env_config_kmeans, env_config_neighbour]\n",
    "config_dict = {'kmeans': env_config_kmeans, 'neighbour':env_config_neighbour}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jpl': 20, 'conv_speed': 208, 'n_machines': 12, 'n_lines': 1, 'window_size': 4, 'isri_dataset': 'isri_dataset', 'next_n': 15, 'last_n': 2, 'input_features': 13, 'obs_space': 'simple', 'diffsum_weight': 0.0, 'DIFFSUM_NORM': 1.0, 'tardiness_weight': 1.0, 'TARDINESS_NORM': 1.0, 'pca': None, 'n_classes': 8, 'cluster_method': 'kmeans'}\n",
      "{'jpl': 20, 'conv_speed': 208, 'n_machines': 12, 'n_lines': 1, 'window_size': 4, 'isri_dataset': 'isri_dataset', 'next_n': 15, 'last_n': 2, 'input_features': 13, 'obs_space': 'simple', 'diffsum_weight': 0.0, 'DIFFSUM_NORM': 1.0, 'tardiness_weight': 1.0, 'TARDINESS_NORM': 1.0, 'pca': None, 'n_classes': 8, 'cluster_method': 'kmeans'}\n",
      "kmeans\n",
      "{'jpl': 20, 'conv_speed': 208, 'n_machines': 12, 'n_lines': 1, 'window_size': 4, 'isri_dataset': 'isri_dataset', 'next_n': 15, 'last_n': 2, 'input_features': 13, 'obs_space': 'simple', 'diffsum_weight': 0.0, 'DIFFSUM_NORM': 1.0, 'tardiness_weight': 1.0, 'TARDINESS_NORM': 1.0, 'pca': None, 'n_classes': 8, 'cluster_method': 'neighbour'}\n",
      "{'jpl': 20, 'conv_speed': 208, 'n_machines': 12, 'n_lines': 1, 'window_size': 4, 'isri_dataset': 'isri_dataset', 'next_n': 15, 'last_n': 2, 'input_features': 13, 'obs_space': 'simple', 'diffsum_weight': 0.0, 'DIFFSUM_NORM': 1.0, 'tardiness_weight': 1.0, 'TARDINESS_NORM': 1.0, 'pca': None, 'n_classes': 8, 'cluster_method': 'neighbour'}\n",
      "neighbour\n"
     ]
    }
   ],
   "source": [
    "for name, i in config_dict.items():\n",
    "    print(i)\n",
    "    print(str(i))\n",
    "    print(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key1': 10, 'key2': 'x', 'key3': True}, {'key1': 10, 'key2': 'x', 'key3': False}, {'key1': 10, 'key2': 'y', 'key3': True}, {'key1': 10, 'key2': 'y', 'key3': False}, {'key1': 20, 'key2': 'x', 'key3': True}, {'key1': 20, 'key2': 'x', 'key3': False}, {'key1': 20, 'key2': 'y', 'key3': True}, {'key1': 20, 'key2': 'y', 'key3': False}]\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Ursprungs-Dictionary\n",
    "original_dict = {\n",
    "    'a': 1,\n",
    "    'b': 2,\n",
    "    'c': 3\n",
    "}\n",
    "\n",
    "# Dictionaries mit zusätzlichen Werten\n",
    "additional_dicts = {\n",
    "    'key1': [10, 20],\n",
    "    'key2': ['x', 'y'],\n",
    "    'key3': [True, False]\n",
    "}\n",
    "\n",
    "# Generieren aller Kombinationen der zusätzlichen Werte\n",
    "keys, values = zip(*additional_dicts.items())\n",
    "combinations = [dict(zip(keys, combination)) for combination in product(*values)]\n",
    "print(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key1-10_key2-x_key3-True: {'a': 1, 'b': 2, 'c': 3, 'key1': 10, 'key2': 'x', 'key3': True}\n",
      "key1-10_key2-x_key3-False: {'a': 1, 'b': 2, 'c': 3, 'key1': 10, 'key2': 'x', 'key3': False}\n",
      "key1-10_key2-y_key3-True: {'a': 1, 'b': 2, 'c': 3, 'key1': 10, 'key2': 'y', 'key3': True}\n",
      "key1-10_key2-y_key3-False: {'a': 1, 'b': 2, 'c': 3, 'key1': 10, 'key2': 'y', 'key3': False}\n",
      "key1-20_key2-x_key3-True: {'a': 1, 'b': 2, 'c': 3, 'key1': 20, 'key2': 'x', 'key3': True}\n",
      "key1-20_key2-x_key3-False: {'a': 1, 'b': 2, 'c': 3, 'key1': 20, 'key2': 'x', 'key3': False}\n",
      "key1-20_key2-y_key3-True: {'a': 1, 'b': 2, 'c': 3, 'key1': 20, 'key2': 'y', 'key3': True}\n",
      "key1-20_key2-y_key3-False: {'a': 1, 'b': 2, 'c': 3, 'key1': 20, 'key2': 'y', 'key3': False}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "copies = {}\n",
    "for combination in combinations:\n",
    "    # Generieren des Namens der Kopie basierend auf den Werten\n",
    "    name = \"_\".join(f\"{key}-{value}\" for key, value in combination.items())\n",
    "    \n",
    "    # Erstellen einer Kopie des Original-Dictionaries und Hinzufügen der zusätzlichen Werte\n",
    "    new_dict = original_dict.copy()\n",
    "    new_dict.update(combination)\n",
    "    \n",
    "    # Hinzufügen der neuen Kopie zum Dictionary der Kopien\n",
    "    copies[name] = new_dict\n",
    "\n",
    "# Ausgabe der Kopien\n",
    "for name, copy in copies.items():\n",
    "    print(f\"{name}: {copy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_config_variants = {\n",
    "    \n",
    "    \"last_n\": 3,\n",
    "    \"reward_type\": \"sparse\" #sparse dense combined\n",
    "}\n",
    "type(env_config_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_sparse_15_kmeans\n",
      "{'jpl': 20, 'conv_speed': 208, 'n_machines': 12, 'n_lines': 1, 'window_size': 4, 'isri_dataset': 'isri_dataset', 'next_n': 15, 'input_features': 13, 'obs_space': 'simple', 'diffsum_weight': 1.0, 'DIFFSUM_NORM': 1.0, 'tardiness_weight': 1.0, 'TARDINESS_NORM': 1.0, 'pca': None, 'last_n': 3, 'reward_type': 'sparse', 'n_classes': 15, 'cluster_method': 'kmeans'}\n",
      "_____\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env_config = {\n",
    "    \"jpl\": 20,  # Example values, please adjust according to your needs\n",
    "    \"conv_speed\": 208,\n",
    "    \"n_machines\": 12,\n",
    "    \"n_lines\": 1,\n",
    "    \"window_size\": 4,\n",
    "    \"isri_dataset\": \"isri_dataset\",\n",
    "    \"next_n\": 15,\n",
    "    \"input_features\": 13,  # Example number of features per job\n",
    "    \"obs_space\": 'simple', # simple, full, small\n",
    "    \"diffsum_weight\": 1.0, #diffsum im tausender Bereich\n",
    "    \"DIFFSUM_NORM\": 1.0,\n",
    "    \"tardiness_weight\": 1.0, \n",
    "    \"TARDINESS_NORM\": 1.0,\n",
    "    \"pca\": None\n",
    "}\n",
    "\n",
    "env_config_variants = {\n",
    "    \"last_n\": [3],\n",
    "    \"reward_type\": [\"sparse\"], #sparse dense combined\n",
    "    \"n_classes\": [15], # Muss mit Kmeans übereinstimmen\n",
    "    \"cluster_method\": [\"kmeans\"] #kmeans model übergeben\n",
    "}\n",
    "\n",
    "\n",
    "keys, values = zip(*env_config_variants.items())\n",
    "combinations = [dict(zip(keys, combination)) for combination in product(*values)]\n",
    "envs = {}\n",
    "for combination in combinations:\n",
    "    name = \"_\".join(f\"{value}\" for key, value in combination.items())\n",
    "    new_dict = env_config.copy()\n",
    "    new_dict.update(combination)\n",
    "    envs[name] = new_dict\n",
    "\n",
    "for name, config in envs.items():\n",
    "    for try_idx in range(1):\n",
    "        print(name)\n",
    "        print(config)\n",
    "        print(\"_____\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Train Split\n",
    "from _dir_init import *\n",
    "from isri_optimizer.rl_sequential_agent.environment import IsriEnv\n",
    "import pickle\n",
    "from data_preprocessing import IsriDataset\n",
    "from typing import Dict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "N_TRAINING_INSTANCES = 500 #606\n",
    "GA_SOLUTIONS_PATH = \"IsriDataDict.pkl\" \n",
    "N_TRIES = 1\n",
    "all_indices = list(range(N_TRAINING_INSTANCES))\n",
    "train_indices, test_indices = train_test_split(all_indices, test_size=0.2, random_state=42) \n",
    "\n",
    "isri_dataset = pickle.load(open(GA_SOLUTIONS_PATH, 'rb'))\n",
    "\n",
    "isri_dataset_train = {}\n",
    "isri_dataset_test = {}\n",
    "\n",
    "\n",
    "isri_dataset_train['Jobdata'] = [isri_dataset['Jobdata'][i] for i in train_indices]\n",
    "isri_dataset_train['Files'] = [isri_dataset['Files'][i] for i in train_indices]\n",
    "isri_dataset_train['GAChromosome'] = [isri_dataset['GAChromosome'][i] for i in train_indices]\n",
    "isri_dataset_train['GAFitness'] = [isri_dataset['GAFitness'][i] for i in train_indices]\n",
    "\n",
    "isri_dataset_test['Jobdata'] = [isri_dataset['Jobdata'][i] for i in test_indices]\n",
    "isri_dataset_test['Files'] = [isri_dataset['Files'][i] for i in test_indices]\n",
    "isri_dataset_test['GAChromosome'] = [isri_dataset['GAChromosome'][i] for i in test_indices]\n",
    "isri_dataset_test['GAFitness'] = [isri_dataset['GAFitness'][i] for i in test_indices]\n",
    "\n",
    "isri_dataset['Jobdata'] = isri_dataset['Jobdata'][:N_TRAINING_INSTANCES]\n",
    "isri_dataset['Files'] = isri_dataset['Files'][:N_TRAINING_INSTANCES]\n",
    "isri_dataset['GAChromosome'] = isri_dataset['GAChromosome'][:N_TRAINING_INSTANCES]\n",
    "isri_dataset['GAFitness'] = isri_dataset['GAFitness'][:N_TRAINING_INSTANCES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(isri_dataset_train['Jobdata'])\n",
    "len(isri_dataset_train['Jobdata'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{23029610520: {'times': [101.52,\n",
       "   93.48,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   74.16000000000001,\n",
       "   129.47999999999996,\n",
       "   98.64000000000001,\n",
       "   106.68,\n",
       "   77.22,\n",
       "   98.58,\n",
       "   88.07999999999998,\n",
       "   131.27999999999997],\n",
       "  'due_date': 3600.0,\n",
       "  'group': 4285022,\n",
       "  'job_id': 23029610520},\n",
       " 23029610522: {'times': [101.52,\n",
       "   93.48,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   76.50000000000001,\n",
       "   92.10000000000001,\n",
       "   68.94,\n",
       "   75.0,\n",
       "   77.22,\n",
       "   98.58,\n",
       "   79.44,\n",
       "   136.2],\n",
       "  'due_date': 3780.0,\n",
       "  'group': 4285094,\n",
       "  'job_id': 23029610522},\n",
       " 23029610528: {'times': [101.52,\n",
       "   93.48,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   74.16000000000001,\n",
       "   117.53999999999999,\n",
       "   98.64000000000001,\n",
       "   102.12,\n",
       "   77.22,\n",
       "   98.58,\n",
       "   88.07999999999998,\n",
       "   141.71999999999997],\n",
       "  'due_date': 4140.0,\n",
       "  'group': 4284926,\n",
       "  'job_id': 23029610528},\n",
       " 23029610531: {'times': [111.06,\n",
       "   101.22,\n",
       "   69.90000000000002,\n",
       "   90.84000000000003,\n",
       "   113.16000000000001,\n",
       "   92.10000000000001,\n",
       "   68.94,\n",
       "   76.98,\n",
       "   77.22,\n",
       "   103.98,\n",
       "   78.89999999999999,\n",
       "   139.25999999999996],\n",
       "  'due_date': 4320.0,\n",
       "  'group': 4285028,\n",
       "  'job_id': 23029610531},\n",
       " 23029610537: {'times': [101.52,\n",
       "   93.48,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   76.50000000000001,\n",
       "   117.53999999999999,\n",
       "   98.64000000000001,\n",
       "   81.12,\n",
       "   77.22,\n",
       "   98.58,\n",
       "   88.61999999999999,\n",
       "   136.2],\n",
       "  'due_date': 4860.0,\n",
       "  'group': 4285086,\n",
       "  'job_id': 23029610537},\n",
       " 23029610542: {'times': [110.69999999999999,\n",
       "   316.44000000000005,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   18.36,\n",
       "   88.68,\n",
       "   68.94,\n",
       "   80.76,\n",
       "   104.58,\n",
       "   98.58,\n",
       "   88.61999999999999,\n",
       "   150.11999999999998],\n",
       "  'due_date': 5220.0,\n",
       "  'group': 4284524,\n",
       "  'job_id': 23029610542},\n",
       " 23029610553: {'times': [101.52,\n",
       "   93.48,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   74.16000000000001,\n",
       "   129.47999999999996,\n",
       "   98.64000000000001,\n",
       "   106.68,\n",
       "   77.22,\n",
       "   98.58,\n",
       "   88.07999999999998,\n",
       "   131.27999999999997],\n",
       "  'due_date': 5400.0,\n",
       "  'group': 4284994,\n",
       "  'job_id': 23029610553},\n",
       " 23029610558: {'times': [98.46,\n",
       "   93.48,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   18.36,\n",
       "   88.68,\n",
       "   68.94,\n",
       "   80.76,\n",
       "   104.58,\n",
       "   98.58,\n",
       "   75.66,\n",
       "   150.11999999999998],\n",
       "  'due_date': 5760.0,\n",
       "  'group': 4285074,\n",
       "  'job_id': 23029610558},\n",
       " 23029610561: {'times': [121.79999999999998,\n",
       "   316.44000000000005,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   18.36,\n",
       "   127.61999999999999,\n",
       "   98.64000000000001,\n",
       "   124.98,\n",
       "   77.22,\n",
       "   98.58,\n",
       "   97.79999999999998,\n",
       "   146.76],\n",
       "  'due_date': 5940.0,\n",
       "  'group': 4285737,\n",
       "  'job_id': 23029610561},\n",
       " 23029610563: {'times': [98.46,\n",
       "   93.48,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   18.36,\n",
       "   92.10000000000001,\n",
       "   68.94,\n",
       "   75.0,\n",
       "   77.22,\n",
       "   98.58,\n",
       "   75.66,\n",
       "   131.27999999999997],\n",
       "  'due_date': 6120.0,\n",
       "  'group': 4285014,\n",
       "  'job_id': 23029610563},\n",
       " 23029610568: {'times': [110.69999999999999,\n",
       "   316.44000000000005,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   18.36,\n",
       "   114.11999999999999,\n",
       "   98.64000000000001,\n",
       "   86.88000000000001,\n",
       "   104.58000000000001,\n",
       "   98.58,\n",
       "   97.79999999999998,\n",
       "   150.11999999999998],\n",
       "  'due_date': 6480.0,\n",
       "  'group': 4284931,\n",
       "  'job_id': 23029610568},\n",
       " 23029610572: {'times': [101.52,\n",
       "   93.48,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   76.50000000000001,\n",
       "   92.10000000000001,\n",
       "   68.94,\n",
       "   75.0,\n",
       "   77.22,\n",
       "   98.58,\n",
       "   79.44,\n",
       "   136.2],\n",
       "  'due_date': 6660.0,\n",
       "  'group': 4285075,\n",
       "  'job_id': 23029610572},\n",
       " 23029610578: {'times': [122.16,\n",
       "   101.22,\n",
       "   69.9,\n",
       "   90.84000000000003,\n",
       "   113.16000000000003,\n",
       "   139.55999999999997,\n",
       "   98.64000000000001,\n",
       "   160.26,\n",
       "   77.22,\n",
       "   103.98,\n",
       "   88.07999999999998,\n",
       "   154.73999999999998],\n",
       "  'due_date': 7200.0,\n",
       "  'group': 4285005,\n",
       "  'job_id': 23029610578},\n",
       " 23029610580: {'times': [101.52,\n",
       "   93.48,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   74.16000000000001,\n",
       "   88.68,\n",
       "   68.94,\n",
       "   80.76,\n",
       "   104.58,\n",
       "   98.58,\n",
       "   78.89999999999999,\n",
       "   150.11999999999998],\n",
       "  'due_date': 7380.0,\n",
       "  'group': 4284924,\n",
       "  'job_id': 23029610580},\n",
       " 23029610584: {'times': [101.52,\n",
       "   93.48,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   74.16000000000001,\n",
       "   92.10000000000001,\n",
       "   68.94,\n",
       "   75.0,\n",
       "   77.22,\n",
       "   98.58,\n",
       "   78.89999999999999,\n",
       "   131.27999999999997],\n",
       "  'due_date': 7560.0,\n",
       "  'group': 4284861,\n",
       "  'job_id': 23029610584},\n",
       " 23029610586: {'times': [98.46,\n",
       "   93.48,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   20.7,\n",
       "   114.11999999999999,\n",
       "   98.64000000000001,\n",
       "   86.88000000000001,\n",
       "   104.58000000000001,\n",
       "   98.58,\n",
       "   85.38,\n",
       "   155.03999999999996],\n",
       "  'due_date': 7740.0,\n",
       "  'group': 4285103,\n",
       "  'job_id': 23029610586},\n",
       " 23029610591: {'times': [112.62,\n",
       "   93.48,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   74.16000000000001,\n",
       "   139.55999999999997,\n",
       "   98.64000000000001,\n",
       "   150.54,\n",
       "   77.22,\n",
       "   98.58,\n",
       "   88.07999999999998,\n",
       "   146.76],\n",
       "  'due_date': 8100.0,\n",
       "  'group': 4284873,\n",
       "  'job_id': 23029610591},\n",
       " 23029610597: {'times': [101.52,\n",
       "   93.48,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   74.16000000000001,\n",
       "   129.47999999999996,\n",
       "   98.64000000000001,\n",
       "   106.68,\n",
       "   77.22,\n",
       "   98.58,\n",
       "   88.07999999999998,\n",
       "   131.27999999999997],\n",
       "  'due_date': 8460.0,\n",
       "  'group': 4284981,\n",
       "  'job_id': 23029610597},\n",
       " 23029610599: {'times': [122.16,\n",
       "   101.22,\n",
       "   69.90000000000002,\n",
       "   90.84000000000003,\n",
       "   113.16000000000003,\n",
       "   124.19999999999999,\n",
       "   98.64000000000001,\n",
       "   172.98,\n",
       "   92.76000000000002,\n",
       "   103.98,\n",
       "   63.06,\n",
       "   227.28000000000003],\n",
       "  'due_date': 8640.0,\n",
       "  'group': 4285059,\n",
       "  'job_id': 23029610599},\n",
       " 23029610604: {'times': [101.52,\n",
       "   93.48,\n",
       "   72.78,\n",
       "   0.0,\n",
       "   74.16000000000001,\n",
       "   92.10000000000001,\n",
       "   68.94,\n",
       "   75.0,\n",
       "   77.22,\n",
       "   98.58,\n",
       "   78.89999999999999,\n",
       "   131.27999999999997],\n",
       "  'due_date': 9000.0,\n",
       "  'group': 4284881,\n",
       "  'job_id': 23029610604}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isri_dataset.keys()\n",
    "isri_dataset['Jobdata'][0]\n",
    "#len(isri_dataset['Jobdata'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Instance Size\n",
    "from _dir_init import *\n",
    "from isri_optimizer.rl_sequential_agent.environment import IsriEnv\n",
    "import pickle\n",
    "from data_preprocessing import IsriDataset\n",
    "from typing import Dict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "def adjust_entry_length(entry, all_entries, min_length=20, max_length=100):\n",
    "    target_length = random.randint(min_length, max_length)\n",
    "    current_length = len(entry)\n",
    "    \n",
    "    if current_length < target_length:\n",
    "        additional_entries = []\n",
    "        for other_entry in all_entries:\n",
    "            if len(other_entry) > 0 and other_entry != entry:\n",
    "                additional_entries.extend(other_entry.items())\n",
    "                if len(entry) + len(additional_entries) >= target_length:\n",
    "                    break\n",
    "        additional_entries = additional_entries[:target_length - current_length]\n",
    "        entry.update(additional_entries)\n",
    "        \n",
    "    elif current_length > target_length:\n",
    "        keys_to_keep = random.sample(list(entry.keys()), target_length)\n",
    "        entry = {key: entry[key] for key in keys_to_keep}\n",
    "        \n",
    "    return entry\n",
    "\n",
    "GA_SOLUTIONS_PATH = \"IsriDataDict.pkl\" \n",
    "isri_dataset = pickle.load(open(GA_SOLUTIONS_PATH, 'rb'))\n",
    "N_TRAINING_INSTANCES = 500 #len(isri_dataset['Jobdata'])\n",
    "\n",
    "all_indices = list(range(N_TRAINING_INSTANCES))\n",
    "train_indices, test_indices = train_test_split(all_indices, test_size=0.2, random_state=42) \n",
    "\n",
    "all_jobdata_entries = isri_dataset['Jobdata']\n",
    "isri_dataset_train = {'Jobdata': [adjust_entry_length(isri_dataset['Jobdata'][i], all_jobdata_entries) for i in train_indices]}\n",
    "isri_dataset_test = {'Jobdata': [adjust_entry_length(isri_dataset['Jobdata'][i], all_jobdata_entries) for i in test_indices]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "isri_dataset_train['Jobdata'][0]\n",
    "len(isri_dataset_train['Jobdata'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Masterarbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
